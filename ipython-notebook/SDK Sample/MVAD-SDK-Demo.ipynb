{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Anomaly Detection Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Prerequisites](#pre)\n",
    "3. [Train a Model](#train)\n",
    "4. [List Models](#list)\n",
    "5. [Inference](#inference)\n",
    "6. [Analysis (for reference only)](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdution <a class=\"anchor\" id=\"intro\"></a>\n",
    "This notebook shows how to use [Multivariate Anomaly Detection](https://docs.microsoft.com/en-us/azure/cognitive-services/anomaly-detector/overview-multivariate) in Anomaly Detector service. Please follow the steps to try it out, you can either [join Teams Group](https://forms.office.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRxSkyhztUNZCtaivu8nmhd1UQ1VFRDA0V1dUMDJRMFhOTzFHQ1lDTVozWi4u) for any questions, or email us via AnomalyDetector@microsoft.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prerequisites <a class=\"anchor\" id=\"pre\"></a>\n",
    "\n",
    "\n",
    "* [Create an Azure subscription](https://azure.microsoft.com/free/cognitive-services) if you don't have one.\n",
    "* [Create an Anomaly Detector resource](https://ms.portal.azure.com/#create/Microsoft.CognitiveServicesAnomalyDetector) and get your `endpoint` and `key`, you'll use these later.\n",
    "* (**optional**) [Install Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli) A helpful tool to manipulate your Azure resources. You can use Azure CLI to retrieve credential information without pasting them as plain text.\n",
    "* (**optional**) Login with Azure CLI `az login`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Install** the anomaly detector SDK and storage packages using following codes ‚¨áÔ∏è, and **import** packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install required packages. Use the following commands to install the anomaly detector SDK and required packages.\n",
    "# ! pip install --upgrade azure-ai-anomalydetector\n",
    "# ! pip install azure-storage-blob\n",
    "# ! pip install azure-mgmt-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install optional packages to see interactive visualization in this Jupyter notebook.\n",
    "# ! pip install plotly==5.5.0\n",
    "# ! pip install notebook>=5.3 \n",
    "# ! pip install ipywidgets>=7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import related packages:\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "from datetime import datetime\n",
    "from azure.ai.anomalydetector import AnomalyDetectorClient\n",
    "from azure.ai.anomalydetector.models import DetectionRequest, ModelInfo, LastDetectionRequest, VariableValues\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# This is to build interactive plot:\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will use a simulated dataset **([multivariate_sample_data.csv](https://github.com/Azure-Samples/AnomalyDetector/blob/master/ipython-notebook/SDK%20Sample/multivariate_sample_data.csv))** in the Github repository. This dataset contains five variables which represent different variables from an equipment.\n",
    "\n",
    "If you'd like to use your own dataset to run this notebook, you should do the following steps first (üé¨[video instruction](https://msit.microsoftstream.com/video/afa00840-98dc-ae72-fad1-f1ec0fe830c1)/[video backup](https://github.com/Azure-Samples/AnomalyDetector/blob/master/ipython-notebook/media/How%20to%20generate%20a%20SAS.mp4)):\n",
    "1. (optional) Split your full csv files into individual csv files that each file contains the data for one variable.\n",
    "1. Compress your local csv files(one metric per file), see [input data schema](https://docs.microsoft.com/en-us/azure/cognitive-services/anomaly-detector/concepts/best-practices-multivariate#input-data-schema)..\n",
    "1. Upload the compressed file to Azure Blob.\n",
    "1. Generate an `SAS URL` for your compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opticalLFiltered</th>\n",
       "      <th>opticalRFiltered</th>\n",
       "      <th>pumpPressure</th>\n",
       "      <th>rotational</th>\n",
       "      <th>vibrationHorizon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-18T13:50:00Z</th>\n",
       "      <td>0.093917</td>\n",
       "      <td>0.081611</td>\n",
       "      <td>0.959366</td>\n",
       "      <td>0.004735</td>\n",
       "      <td>0.934785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18T14:00:00Z</th>\n",
       "      <td>0.087634</td>\n",
       "      <td>0.085192</td>\n",
       "      <td>0.957706</td>\n",
       "      <td>0.027995</td>\n",
       "      <td>0.933875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18T14:10:00Z</th>\n",
       "      <td>0.108739</td>\n",
       "      <td>0.117380</td>\n",
       "      <td>0.954204</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>0.923942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18T14:20:00Z</th>\n",
       "      <td>0.127014</td>\n",
       "      <td>0.145632</td>\n",
       "      <td>0.947601</td>\n",
       "      <td>0.079059</td>\n",
       "      <td>0.944030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18T14:30:00Z</th>\n",
       "      <td>0.156628</td>\n",
       "      <td>0.138406</td>\n",
       "      <td>0.951069</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>0.923689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T22:40:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T22:50:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:00:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:10:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:20:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30010 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      opticalLFiltered  opticalRFiltered  pumpPressure  \\\n",
       "timestamp                                                                \n",
       "2021-02-18T13:50:00Z          0.093917          0.081611      0.959366   \n",
       "2021-02-18T14:00:00Z          0.087634          0.085192      0.957706   \n",
       "2021-02-18T14:10:00Z          0.108739          0.117380      0.954204   \n",
       "2021-02-18T14:20:00Z          0.127014          0.145632      0.947601   \n",
       "2021-02-18T14:30:00Z          0.156628          0.138406      0.951069   \n",
       "...                                ...               ...           ...   \n",
       "2021-09-14T22:40:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T22:50:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:00:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:10:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:20:00Z          0.000000          0.000000      0.950000   \n",
       "\n",
       "                      rotational  vibrationHorizon  \n",
       "timestamp                                           \n",
       "2021-02-18T13:50:00Z    0.004735          0.934785  \n",
       "2021-02-18T14:00:00Z    0.027995          0.933875  \n",
       "2021-02-18T14:10:00Z    0.049488          0.923942  \n",
       "2021-02-18T14:20:00Z    0.079059          0.944030  \n",
       "2021-02-18T14:30:00Z    0.088172          0.923689  \n",
       "...                          ...               ...  \n",
       "2021-09-14T22:40:00Z    0.000000          0.850000  \n",
       "2021-09-14T22:50:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:00:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:10:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:20:00Z    0.000000          0.850000  \n",
       "\n",
       "[30010 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data visualization\n",
    "df = pd.read_csv(\"multivariate_sample_data.csv\", index_col=\"timestamp\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's draw an interactive plot. You may zoom in/out through clicking 'autoscale' and select an area or select a variabe for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = \"2021-02-18T13:50:00Z\"\n",
    "end_time = \"2021-03-04T13:50:00Z\"\n",
    "df[(df.index > start_time) & (df.index < end_time)].plot(title='Sample data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data overview](../media/data-overview.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code to generate SAS (for reference only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.storage.blob import BlobClient, BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "from datetime import datetime, timedelta\n",
    "import zipfile\n",
    "\n",
    "BLOB_SAS_TEMPLATE = \"https://{account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n",
    "\n",
    "\n",
    "def zip_file(root, name):\n",
    "    \"\"\"\n",
    "    A helper function to compress local csv files.\n",
    "    :param root: root directory of csv files\n",
    "    :param name: name of the compressed file (with suffix) \n",
    "    \"\"\"\n",
    "    z = zipfile.ZipFile(name, \"w\", zipfile.ZIP_DEFLATED)\n",
    "    for f in os.listdir(root):\n",
    "        if f.endswith(\"csv\"):\n",
    "            z.write(os.path.join(root, f), f)\n",
    "    z.close()\n",
    "    print(\"Compress files success!\")\n",
    "\n",
    "\n",
    "def upload_to_blob(file, conn_str, container, blob_name):\n",
    "    \"\"\"\n",
    "    A helper function to upload files to blob\n",
    "    :param file: the path to the file to be uploaded\n",
    "    :param conn_str: the connection string of the target storage account\n",
    "    :param container: the container name in the storage account\n",
    "    :param blob_name: the blob name in the container\n",
    "    \"\"\"\n",
    "    blob_client = BlobClient.from_connection_string(conn_str, container_name=container, blob_name=blob_name)\n",
    "    with open(file, \"rb\") as f:\n",
    "        blob_client.upload_blob(f, overwrite=True)\n",
    "    print(\"Upload Success!\")\n",
    "\n",
    "\n",
    "def generate_data_source_sas(conn_str, container, blob_name):\n",
    "    \"\"\"\n",
    "    A helper function to generate blob SAS.\n",
    "    :param conn_str: the connection string of the target storage account\n",
    "    :param container: the container name in the storage account\n",
    "    :param blob_name: the blob name in the container\n",
    "    :return: generated SAS\n",
    "    \"\"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(conn_str=conn_str)\n",
    "    sas_token = generate_blob_sas(account_name=blob_service_client.account_name,\n",
    "                                  container_name=container,\n",
    "                                  blob_name=blob_name,\n",
    "                                  account_key=blob_service_client.credential.account_key,\n",
    "                                  permission=BlobSasPermissions(read=True),\n",
    "                                  expiry=datetime.utcnow() + timedelta(days=1))\n",
    "    blob_sas = BLOB_SAS_TEMPLATE.format(account_name=blob_service_client.account_name,\n",
    "                                        container_name=container,\n",
    "                                        blob_name=blob_name,\n",
    "                                        sas_token=sas_token)\n",
    "    return blob_sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"sample_data_MVAD\"\n",
    "zipfile_name = \"sample_data_MVAD.zip\"\n",
    "account_name = \"[Your storage account name]\"   # storage account name\n",
    "resource_group = \"[Your resource group name]\"  # resource group\n",
    "try:\n",
    "    cmd = f\"az storage account keys list -g {resource_group} -n {account_name}\"   # using az-cli is safer\n",
    "    az_response = subprocess.run(cmd.split(\" \"), stdout=subprocess.PIPE).stdout\n",
    "    key = json.loads(az_response)[0][\"value\"]\n",
    "    connection_string = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={key};EndpointSuffix=core.windows.net\"\n",
    "except FileNotFoundError:    # no az-cli available\n",
    "    connection_string = os.getenv(\"STORAGE_CONN_STR\")\n",
    "container_name = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compress files success!\n",
      "Upload Success!\n",
      "Blob SAS url: https://mvadsample.blob.core.windows.net/data/sample_data_MVAD.zip?se=2022-03-25T09%3A57%3A50Z&sp=rt&sv=2020-10-02&sr=b&sig=Y98F0YS93ho8EOhnyQ5lGSojEOKdn76ISMuboUgXNnU%3D\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "os.makedirs(source_folder, exist_ok=True)\n",
    "for variable in df.columns:\n",
    "    individual_df = pd.DataFrame(df[variable].values, index=df.index, columns=[\"value\"])\n",
    "    individual_df.to_csv(os.path.join(source_folder, f\"{variable}.csv\"))\n",
    "    \n",
    "zip_file(source_folder, zipfile_name)\n",
    "upload_to_blob(zipfile_name, connection_string, container_name, zipfile_name)\n",
    "data_source = generate_data_source_sas(connection_string, container_name, zipfile_name)\n",
    "print(\"Blob SAS url: \" + data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a model <a class=\"anchor\" id=\"train\"></a>\n",
    "\n",
    "Before you train a model, you should specify the `subscription key` and `endpoint` of your Anomaly Detector service to create an Anomaly Detector client in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you create an Anomaly Detector resource in Azure portal, you will get the endpoint and key, and put them here.\n",
    "try:\n",
    "    resource_group = \"[Your resource group name]\"\n",
    "    account_name = \"[Your account name]\"\n",
    "    cmd = f\"az cognitiveservices account keys list -g {resource_group} -n {account_name}\"   # using az-cli is safer\n",
    "    az_response = subprocess.run(cmd.split(\" \"), stdout=subprocess.PIPE).stdout\n",
    "    subscription_key = json.loads(az_response)[\"key1\"]\n",
    "    anomaly_detector_endpoint = f\"https://{account_name}.cognitiveservices.azure.com\"\n",
    "except FileNotFoundError:\n",
    "    subscription_key = os.getenv(\"SUB_KEY\")\n",
    "    anomaly_detector_endpoint = os.getenv(\"AD_ENDPOINT\")\n",
    "# Create an Anomaly Detector client.\n",
    "ad_client = AnomalyDetectorClient(AzureKeyCredential(subscription_key), anomaly_detector_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify the timespan of training data using `start_time` and `end_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = \"2021-02-18T13:50:00Z\"\n",
    "end_time = \"2021-09-01T00:00:00Z\"\n",
    "sliding_window = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feed = ModelInfo(start_time=start_time, end_time=end_time, source=data_source, sliding_window=sliding_window)\n",
    "response_header = ad_client.train_multivariate_model(data_feed, cls=lambda *args: [args[i] for i in range(len(args))])[-1]\n",
    "trained_model_id = response_header['Location'].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model id: cd5170c8-ab59-11ec-a670-b2e8cb708e18\n"
     ]
    }
   ],
   "source": [
    "print(f\"model id: {trained_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Status\n",
    "‚òïÔ∏èTraining process might take few minutes to few hours (depending on the data size, in this sample case it'll take you within 3 minutes), take a cup of coffee and come back then, waiting for its status to be **READY**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model status: READY\n"
     ]
    }
   ],
   "source": [
    "model_status = ad_client.get_multivariate_model(trained_model_id).model_info.status\n",
    "print(f\"model status: {model_status}\")\n",
    "\n",
    "#If the model status is failed, run the following code to see the error message.\n",
    "#print ([x.code + ' ' + x.message for x in train_response.model_info.errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ad_client.get_multivariate_model(trained_model_id).model_info.errors[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get model information and track training progress.\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "model = ad_client.get_multivariate_model(trained_model_id)\n",
    "current_epoch = 0 if len(model.model_info.diagnostics_info.model_state.epoch_ids) == 0 else model.model_info.diagnostics_info.model_state.epoch_ids[-1]\n",
    "print(f\"training progress: {current_epoch}/100.\")\n",
    "if model.model_info.status == \"READY\":\n",
    "    model_state = model.model_info.diagnostics_info.model_state\n",
    "    epoch_ids = model_state.epoch_ids\n",
    "    train_losses = model_state.train_losses\n",
    "    validation_losses = model_state.validation_losses\n",
    "    latency = model_state.latencies_in_seconds\n",
    "    loss_summary = pd.DataFrame({\n",
    "        \"epoch_id\": epoch_ids, \n",
    "        \"train_loss\": train_losses, \n",
    "        \"validation_loss\": validation_losses,\n",
    "        \"latency\": latency\n",
    "    })\n",
    "    display(loss_summary)\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    fig.add_trace(go.Scatter(x=epoch_ids, y=train_losses, \n",
    "                             mode='lines',\n",
    "                             name='train losses'))\n",
    "    fig.add_trace(go.Scatter(x=epoch_ids, y=validation_losses,\n",
    "                             mode='lines',\n",
    "                             name='validation losses'))\n",
    "    fig.add_trace(go.Scatter(x=epoch_ids, y=latency,\n",
    "                             mode='markers', name='latency'),\n",
    "                  secondary_y=True)\n",
    "    fig.update_layout(\n",
    "        title_text=\"Visualization of training progress\"\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Epoch IDs\")\n",
    "\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"Loss value\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Latency (s)\", secondary_y=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  List Models <a class=\"anchor\" id=\"list\"></a>\n",
    "List models that have been trained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd5170c8-ab59-11ec-a670-b2e8cb708e18</td>\n",
       "      <td>READY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9db32770-ab50-11ec-a670-b2e8cb708e18</td>\n",
       "      <td>READY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8d8811a6-ab48-11ec-b575-b2e8cb708e18</td>\n",
       "      <td>READY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ee90bdb4-ab47-11ec-822b-b2e8cb708e18</td>\n",
       "      <td>FAILED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6e7d9b7e-ab47-11ec-b714-e2151d0110f3</td>\n",
       "      <td>FAILED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model_id  status\n",
       "0  cd5170c8-ab59-11ec-a670-b2e8cb708e18   READY\n",
       "1  9db32770-ab50-11ec-a670-b2e8cb708e18   READY\n",
       "2  8d8811a6-ab48-11ec-b575-b2e8cb708e18   READY\n",
       "3  ee90bdb4-ab47-11ec-822b-b2e8cb708e18  FAILED\n",
       "4  6e7d9b7e-ab47-11ec-b714-e2151d0110f3  FAILED"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_list = list(ad_client.list_multivariate_model(skip=0, top=100))\n",
    "model_summary = pd.DataFrame([{\"model_id\": m.model_id, \"status\": m.status} for m in model_list[:5]])\n",
    "display(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_properties': {},\n",
       " 'model_id': 'cd5170c8-ab59-11ec-a670-b2e8cb708e18',\n",
       " 'created_time': datetime.datetime(2022, 3, 24, 10, 4, 32, tzinfo=<isodate.tzinfo.Utc object at 0x7f3eb778afd0>),\n",
       " 'last_updated_time': datetime.datetime(2022, 3, 24, 10, 9, 29, tzinfo=<isodate.tzinfo.Utc object at 0x7f3eb778afd0>),\n",
       " 'status': 'READY',\n",
       " 'display_name': '',\n",
       " 'variables_count': 5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first model\n",
    "model = model_list[0]\n",
    "vars(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference <a class=\"anchor\" id=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Inference asynchronously\n",
    "\n",
    "You should inference first and get a result id, then use the id to get the detection result.\n",
    "- Specify the time span of inference data using `start_time` and `end_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the start time and end time for inference.\n",
    "start_inference_time = \"2021-09-01T00:00:00Z\"\n",
    "end_inference_time = \"2021-09-14T23:20:00Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result id: b876ee02-ab5a-11ec-a670-b2e8cb708e18\n"
     ]
    }
   ],
   "source": [
    "detection_req = DetectionRequest(source=data_source, start_time=start_inference_time, end_time=end_inference_time)\n",
    "response_header = ad_client.detect_anomaly(trained_model_id, detection_req, cls=lambda *args: [args[i] for i in range(len(args))])[-1]\n",
    "result_id = response_header['Location'].split(\"/\")[-1]\n",
    "print(f\"result id: {result_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get inference status\n",
    "‚òïÔ∏èInference process might\n",
    "take 10-20mins (depending on the data size). Take a cup of coffee and come back then, and waiting for its status to be **READY**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result status: READY\n"
     ]
    }
   ],
   "source": [
    "r = ad_client.get_detection_result(result_id)\n",
    "print(f\"result status: {r.summary.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'is_anomaly': True, 'severity': 0.06823510676622391, 'score': 0.11724714934825897, 'interpretation': [<azure.ai.anomalydetector.models._models_py3.AnomalyInterpretation object at 0x7f3e980502e0>, <azure.ai.anomalydetector.models._models_py3.AnomalyInterpretation object at 0x7f3e98050160>, <azure.ai.anomalydetector.models._models_py3.AnomalyInterpretation object at 0x7f3e98050310>, <azure.ai.anomalydetector.models._models_py3.AnomalyInterpretation object at 0x7f3e980503d0>, <azure.ai.anomalydetector.models._models_py3.AnomalyInterpretation object at 0x7f3e980506a0>]}\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first anomalous result of inference.\n",
    "for r_item in r.results:\n",
    "    if r_item.value.is_anomaly:\n",
    "        print(r_item.value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Inference with the synchronous API (NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This synchronous API will get detection result immediately after you call it, you should put your data with JSON format into the request body, and specify how much data points you'd like to detect within the `detectingPoints` field, which could be a number **between 1 and 10**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>is_anomaly</th>\n",
       "      <th>severity</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-12T13:30:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-12T13:40:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-12T13:50:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-12T14:00:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-12T14:10:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-12T14:20:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-09-12T14:30:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-09-12T14:40:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.017843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-09-12T14:50:00Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.131275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-09-12T15:00:00Z</td>\n",
       "      <td>True</td>\n",
       "      <td>0.087801</td>\n",
       "      <td>0.150866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp is_anomaly  severity     score\n",
       "0  2021-09-12T13:30:00Z      False  0.010384  0.017843\n",
       "1  2021-09-12T13:40:00Z      False  0.010384  0.017843\n",
       "2  2021-09-12T13:50:00Z      False  0.010384  0.017843\n",
       "3  2021-09-12T14:00:00Z      False  0.010384  0.017843\n",
       "4  2021-09-12T14:10:00Z      False  0.010384  0.017843\n",
       "5  2021-09-12T14:20:00Z      False  0.010384  0.017843\n",
       "6  2021-09-12T14:30:00Z      False  0.010384  0.017843\n",
       "7  2021-09-12T14:40:00Z      False  0.010384  0.017843\n",
       "8  2021-09-12T14:50:00Z       True  0.076399  0.131275\n",
       "9  2021-09-12T15:00:00Z       True  0.087801  0.150866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "sample_input_df = df[df.index<=\"2021-09-12T15:00:00Z\"][-110:]\n",
    "sample_input = [{\"name\": var, \n",
    "                 \"timestamps\": sample_input_df.index.tolist(), \n",
    "                 \"values\": sample_input_df[var].tolist()} for var in sample_input_df.columns]\n",
    "last_detection_request = LastDetectionRequest(variables=[VariableValues(**item) for item in sample_input], detecting_points=10)\n",
    "res = ad_client.last_detect_anomaly(model_id=trained_model_id, body=last_detection_request)\n",
    "results = pd.DataFrame(columns=[\"timestamp\", \"is_anomaly\", \"severity\", \"score\"])\n",
    "for item in res.results:\n",
    "    results = results.append({\"timestamp\": item.timestamp.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                              \"is_anomaly\": item.value.is_anomaly,\n",
    "                              \"severity\": item.value.severity,\n",
    "                              \"score\": item.value.score}, ignore_index=True)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of detection results (for reference only) <a class=\"anchor\" id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = r.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opticalLFiltered</th>\n",
       "      <th>opticalRFiltered</th>\n",
       "      <th>pumpPressure</th>\n",
       "      <th>rotational</th>\n",
       "      <th>vibrationHorizon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-01T00:00:00Z</th>\n",
       "      <td>0.750092</td>\n",
       "      <td>0.766778</td>\n",
       "      <td>0.303229</td>\n",
       "      <td>0.303962</td>\n",
       "      <td>0.460510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01T00:10:00Z</th>\n",
       "      <td>0.743859</td>\n",
       "      <td>0.766981</td>\n",
       "      <td>0.260823</td>\n",
       "      <td>0.278101</td>\n",
       "      <td>0.415097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01T00:20:00Z</th>\n",
       "      <td>0.762221</td>\n",
       "      <td>0.771264</td>\n",
       "      <td>0.230553</td>\n",
       "      <td>0.321643</td>\n",
       "      <td>0.441945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01T00:30:00Z</th>\n",
       "      <td>0.788647</td>\n",
       "      <td>0.773422</td>\n",
       "      <td>0.263202</td>\n",
       "      <td>0.277294</td>\n",
       "      <td>0.465198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01T00:40:00Z</th>\n",
       "      <td>0.806244</td>\n",
       "      <td>0.812657</td>\n",
       "      <td>0.239769</td>\n",
       "      <td>0.295336</td>\n",
       "      <td>0.443462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T22:40:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T22:50:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:00:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:10:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14T23:20:00Z</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      opticalLFiltered  opticalRFiltered  pumpPressure  \\\n",
       "timestamp                                                                \n",
       "2021-09-01T00:00:00Z          0.750092          0.766778      0.303229   \n",
       "2021-09-01T00:10:00Z          0.743859          0.766981      0.260823   \n",
       "2021-09-01T00:20:00Z          0.762221          0.771264      0.230553   \n",
       "2021-09-01T00:30:00Z          0.788647          0.773422      0.263202   \n",
       "2021-09-01T00:40:00Z          0.806244          0.812657      0.239769   \n",
       "...                                ...               ...           ...   \n",
       "2021-09-14T22:40:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T22:50:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:00:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:10:00Z          0.000000          0.000000      0.950000   \n",
       "2021-09-14T23:20:00Z          0.000000          0.000000      0.950000   \n",
       "\n",
       "                      rotational  vibrationHorizon  \n",
       "timestamp                                           \n",
       "2021-09-01T00:00:00Z    0.303962          0.460510  \n",
       "2021-09-01T00:10:00Z    0.278101          0.415097  \n",
       "2021-09-01T00:20:00Z    0.321643          0.441945  \n",
       "2021-09-01T00:30:00Z    0.277294          0.465198  \n",
       "2021-09-01T00:40:00Z    0.295336          0.443462  \n",
       "...                          ...               ...  \n",
       "2021-09-14T22:40:00Z    0.000000          0.850000  \n",
       "2021-09-14T22:50:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:00:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:10:00Z    0.000000          0.850000  \n",
       "2021-09-14T23:20:00Z    0.000000          0.850000  \n",
       "\n",
       "[2013 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view inference data\n",
    "test_df = df.loc[\"2021-09-01T00:00:00Z\":\"2021-09-14T23:20:00Z\"]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_anomalies = []\n",
    "sev = []\n",
    "scores = []\n",
    "sensitivity = 0.7\n",
    "for item in results:\n",
    "    if item.value:\n",
    "        is_anomalies.append(item.value.is_anomaly)\n",
    "        sev.append(item.value.severity)\n",
    "        scores.append(item.value.score)\n",
    "\n",
    "anomolous_timestamps = []\n",
    "num_contributors = 3\n",
    "top_values = {f\"top_{i}\": [] for i in range(num_contributors)}\n",
    "for ts, item in zip(test_df.index, r.results):\n",
    "    if item.value.is_anomaly and item.value.severity > 1 - sensitivity:\n",
    "        anomolous_timestamps.append(ts)\n",
    "        for i in range(num_contributors):\n",
    "            top_values[f\"top_{i}\"].append(test_df[item.value.interpretation[i].variable][ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
    "colors = [px.colors.sequential.Greys[-1], px.colors.sequential.Greys[-3], px.colors.sequential.Greys[-6]]\n",
    "for v in test_df.columns:\n",
    "    fig.add_trace(go.Scatter(x=test_df.index, y=test_df[v], \n",
    "                             mode='lines',\n",
    "                             name=v),\n",
    "                  row=1, col=1)\n",
    "for i in range(num_contributors):\n",
    "    fig.add_trace(go.Scatter(x=anomolous_timestamps, y=top_values[f\"top_{i}\"],\n",
    "                             mode=\"markers\", name=f\"Top {i+1} contributor\",\n",
    "                             marker=dict(\n",
    "                                color=colors[i],\n",
    "                                size=8,\n",
    "                            )),\n",
    "                  row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=test_df.index, y=scores,\n",
    "                         mode='lines',\n",
    "                         name='score'),\n",
    "              row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=test_df.index, y=sev,\n",
    "                         mode='lines', name='severity'),\n",
    "              row=3, col=1)\n",
    "fig.update_layout(\n",
    "    title_text=\"Visualization of detection results\"\n",
    ")\n",
    "fig.update_yaxes(title_text=\"value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"score\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"severity\", row=3, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data overview](../media/inference-result.png )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43c31cec74771ef500596564a63f179874fac196ff9ba93b3b9618e2a194a9ab"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
