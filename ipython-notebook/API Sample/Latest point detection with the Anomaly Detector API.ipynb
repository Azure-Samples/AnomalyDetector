{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest point anomaly detection with the Anomaly Detector API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this Jupyter notebook to start visualizing anomalies as a batch with the Anomaly Detector API in Python.\n",
    "\n",
    "While you can detect anomalies as a batch, you can also detect the anomaly status of the last data point in the time series. This notebook iteratively sends latest-point anomaly detection requests to the Anomaly Detector API and visualizes the response. The graph created at the end of this notebook will display the following:\n",
    "* Anomalies found while in the data set, highlighted.\n",
    "* Anomaly detection boundaries \n",
    "* Anomalies seen in the data, highlighted.\n",
    "\n",
    "By calling the API on your data's latest points, you can monitor your data as it's created. \n",
    "\n",
    "The following example simulates using the Anomaly Detector API on streaming data. Sections of the example time series are sent to the API over multiple iterations, and the anomaly status of each section's last data point is saved. The data set used in this example has a pattern that repeats roughly every 7 data points (the `period` in the request's JSON file), so for best results, the data set is sent in groups of 29 points (`4 * <period> + an extra data point`. See [Best practices for using the Anomaly Detector API](https://docs.microsoft.com/azure/cognitive-services/anomaly-detector/concepts/anomaly-detection-best-practices) for more information).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start sending requests to the Anomaly Detector API, paste your Anomaly Detector resource access key below,\n",
    "# and replace the endpoint variable with the endpoint for your region or your on-premise container endpoint. \n",
    "# Endpoint examples:\n",
    "# https://westus2.api.cognitive.microsoft.com/anomalydetector/v1.0/timeseries/last/detect\n",
    "# http://127.0.0.1:5000/anomalydetector/v1.0/timeseries/last/detect\n",
    "apikey = '[Placeholder: Your Anomaly Detector resource access key]' \n",
    "endpoint_latest = '[Placeholder: Your Anomaly Detector resource endpoint]/anomalydetector/v1.0/timeseries/last/detect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure,output_notebook, show\n",
    "from bokeh.palettes import Blues4\n",
    "from bokeh.models import ColumnDataSource,Slider\n",
    "import datetime\n",
    "from bokeh.io import push_notebook\n",
    "from dateutil import parser\n",
    "from ipywidgets import interact, widgets, fixed\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(endpoint, apikey, request_data):\n",
    "    headers = {'Content-Type': 'application/json', 'Ocp-Apim-Subscription-Key': apikey}\n",
    "    response = requests.post(endpoint, data=json.dumps(request_data), headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode(\"utf-8\"))\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        raise Exception(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_figure(result, sample_data, sensitivity):\n",
    "    columns = {'expectedValues': result['expectedValues'], 'isAnomaly': result['isAnomaly'], 'isNegativeAnomaly': result['isNegativeAnomaly'],\n",
    "              'isPositiveAnomaly': result['isPositiveAnomaly'], 'upperMargins': result['upperMargins'], 'lowerMargins': result['lowerMargins']\n",
    "              , 'value': [x['value'] for x in sample_data['series']], 'timestamp': [parser.parse(x['timestamp']) for x in sample_data['series']]}\n",
    "    response = pd.DataFrame(data=columns)\n",
    "    values = response['value']\n",
    "    label = response['timestamp']\n",
    "    anomalies = []\n",
    "    anomaly_labels = []\n",
    "    index = 0\n",
    "    anomaly_indexes = []\n",
    "    p = figure(x_axis_type='datetime', title=\"Anomaly Detection Result ({0} Sensitivity)\".format(sensitivity), width=800, height=600)\n",
    "    for anom in response['isAnomaly']:\n",
    "        if anom == True and (values[index] > response.iloc[index]['expectedValues'] + response.iloc[index]['upperMargins'] or \n",
    "                         values[index] < response.iloc[index]['expectedValues'] - response.iloc[index]['lowerMargins']):\n",
    "            anomalies.append(values[index])\n",
    "            anomaly_labels.append(label[index])\n",
    "            anomaly_indexes.append(index)\n",
    "        index = index+1\n",
    "    upperband = response['expectedValues'] + response['upperMargins']\n",
    "    lowerband = response['expectedValues'] -response['lowerMargins']\n",
    "    band_x = np.append(label, label[::-1])\n",
    "    band_y = np.append(lowerband, upperband[::-1])\n",
    "    boundary = p.patch(band_x, band_y, color=Blues4[2], fill_alpha=0.5, line_width=1, legend='Boundary')\n",
    "    p.line(label, values, legend='value', color=\"#2222aa\", line_width=1)\n",
    "    p.line(label, response['expectedValues'], legend='expectedValue',  line_width=1, line_dash=\"dotdash\", line_color='olivedrab')\n",
    "    anom_source = ColumnDataSource(dict(x=anomaly_labels, y=anomalies))\n",
    "    anoms = p.circle('x', 'y', size=5, color='tomato', source=anom_source)\n",
    "    p.legend.border_line_width = 1\n",
    "    p.legend.background_fill_alpha  = 0.1\n",
    "    show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect latest anomaly of sample timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells call the Anomaly Detector API with an example time series data set and different sensitivities for anomaly detection. Varying the sensitivity of the Anomaly Detector API can improve how well the response fits your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly(sensitivity):\n",
    "    sample_data = json.load(open('univariate_sample_daily.json'))\n",
    "    points = sample_data['series']\n",
    "    skip_point = 29\n",
    "    result = {'expectedValues': [None]*len(points), 'upperMargins': [None]*len(points), \n",
    "              'lowerMargins': [None]*len(points), 'isNegativeAnomaly': [False]*len(points), \n",
    "              'isPositiveAnomaly':[False]*len(points), 'isAnomaly': [False]*len(points)}\n",
    "    anom_count = 0\n",
    "    for i in range(skip_point, len(points)+1):\n",
    "        single_sample_data = {}\n",
    "        single_sample_data['series'] = points[i-29:i]\n",
    "        single_sample_data['granularity'] = 'daily'\n",
    "        single_sample_data['maxAnomalyRatio'] = 0.25\n",
    "        single_sample_data['sensitivity'] = sensitivity\n",
    "        single_point = detect(endpoint_latest, apikey, single_sample_data)\n",
    "        if single_point['isAnomaly'] == True:\n",
    "            anom_count = anom_count + 1\n",
    "\n",
    "        result['expectedValues'][i-1] = single_point['expectedValue']\n",
    "        result['upperMargins'][i-1] = single_point['upperMargin']\n",
    "        result['lowerMargins'][i-1] = single_point['lowerMargin']\n",
    "        result['isNegativeAnomaly'][i-1] = single_point['isNegativeAnomaly']\n",
    "        result['isPositiveAnomaly'][i-1] = single_point['isPositiveAnomaly']\n",
    "        result['isAnomaly'][i-1] = single_point['isAnomaly']\n",
    "    \n",
    "    build_figure(result, sample_data, sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95 sensitvity\n",
    "detect_anomaly(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 85 sensitvity\n",
    "detect_anomaly(85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}